
import streamlit as st
import torch
from indic_transliteration.sanscript import transliterate, DEVANAGARI, ITRANS
from parler_tts import ParlerTTSForConditionalGeneration
from transformers import AutoTokenizer
import soundfile as sf
import numpy as np
import os

# Page configuration
st.set_page_config(
    page_title="Text-to-Speech Generator",
    page_icon="üó£Ô∏è",
    layout="wide"
)

# Custom CSS for better styling
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stButton>button {
        width: 100%;
        margin-top: 1rem;
    }
    .success-message {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d4edda;
        color: #155724;
        margin: 1rem 0;
    }
    </style>
""", unsafe_allow_html=True)

# Title and description
st.title("üó£Ô∏èText-to-Speech Generator")
st.markdown("""
    Convert English text to natural-sounding speech using advanced AI technology.
    This application is specifically trained for Indian male accent.
""")

# Initialize session state for model loading
if 'model' not in st.session_state:
    st.session_state.model = None
if 'tokenizer' not in st.session_state:
    st.session_state.tokenizer = None

def load_models():
    """Load the TTS model and tokenizer"""
    with st.spinner("Loading models... This might take a few moments."):
        device = "cuda:0" if torch.cuda.is_available() else "cpu"
        model = ParlerTTSForConditionalGeneration.from_pretrained(
            "En1gma02/Parler-TTS-Mini-v0.1-Indian-Accent-Kaggle"
        ).to(device)
        tokenizer = AutoTokenizer.from_pretrained("parler-tts/parler_tts_mini_v0.1")
        st.session_state.model = model
        st.session_state.tokenizer = tokenizer
        st.success("‚úÖ Models loaded successfully!")

def generate_audio(text, description, model, tokenizer):
    """Generate audio from input text"""
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    

    
    # Tokenize inputs
    input_ids = tokenizer(description, return_tensors="pt").input_ids.to(device)
    prompt_input_ids = tokenizer(text, return_tensors="pt").input_ids.to(device)
    
    # Generate audio
    with torch.no_grad():
        generation = model.generate(input_ids=input_ids, prompt_input_ids=prompt_input_ids)
    audio_arr = generation.cpu().numpy().squeeze()
    
    return audio_arr

# Sidebar for model loading and information
with st.sidebar:
    st.header("üìö Model Information")
    st.markdown("""
        **Model Details:**
        - Name: Parler-TTS-Mini
        - Version: 0.1
        - Type: Indian Male Accent
    """)
    
    if st.button("Load Model"):
        load_models()

# Main content area
main_col1, main_col2 = st.columns([2, 1])

with main_col1:
    # Text input section
    st.subheader("üìù Input Text")
    input_text = st.text_area(
        "Enter English text input",
        value=input(),
        height=150
    )

with main_col2:
    # Voice settings
    st.subheader("üé§ Voice Settings")
    voice_description = st.text_area(
        "Voice Description",
        value=input(),
        height=150
    )

# Generate button and audio output
if st.button("üéµ Generate Audio"):
    if st.session_state.model is None or st.session_state.tokenizer is None:
        st.warning("‚ö†Ô∏è Please load the model first using the button in the sidebar!")
    else:
        try:
            with st.spinner("üéµ Generating audio..."):
                audio_array = generate_audio(
                    input_text,
                    voice_description,
                    st.session_state.model,
                    st.session_state.tokenizer
                )
                
                # Convert to float32
                audio_array_float32 = audio_array.astype(np.float32)
                
                # Save audio file
                output_path = 'generated_audio.wav'
                sf.write(output_path, audio_array_float32, st.session_state.model.config.sampling_rate)
                
                # Display audio player
                st.subheader("üéß Generated Audio")
                st.audio(output_path)
                
                # Download button
                with open(output_path, 'rb') as f:
                    st.download_button(
                        label="üì• Download Audio",
                        data=f,
                        file_name="indian_accent.wav",
                        mime="audio/wav"
                    )
                
        except Exception as e:
            st.error(f"‚ùå An error occurred: {str(e)}")

# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center'>
        <p>Created with ‚ù§Ô∏è by team DataKraft Corps using Streamlit</p>
    </div>
""", unsafe_allow_html=True)

# Add requirements information
if st.sidebar.checkbox("Show Requirements"):
    st.sidebar.markdown("""
        **Required Packages:**
        ```
        streamlit
        torch
        parler_tts
        transformers
        soundfile
        numpy
        ```
    """)